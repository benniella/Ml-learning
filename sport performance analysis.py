# -*- coding: utf-8 -*-
"""Nig VS Alg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hhc6ATM3g4D2Hrh_ZrqiZemqNa9aPBFw
"""

!pip install ultralytics
!pip install roboflow

#importing the yolo libraries
from ultralytics import YOLO
import os

# uploading the dataset zip file
#generated by generative AI
from google.colab import files
uploaded = files.upload()

# extract the zip file
# generated by generative AI
import zipfile

zip_path = "/content/football-players-detection.v2i.yolov8.zip"
extract_path = "/content/football-players-data"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Train Yolov8 on my dataset
# Train model
model = YOLO('yolov8n.pt')

results = model.train(
    data=f"{extract_path}/data.yaml",
    epochs=20,
    imgsz=640,
    batch=16
)

# Load trained model
trained_model = YOLO('runs/detect/train/weights/best.pt')

# Test on an image
result = trained_model.predict(source='https://ultralytics.com/images/bus.jpg', save=True)

from google.colab import drive
drive.mount('/content/drive')

import os

path = "/content/drive/MyDrive/colab"
print("Files in colab folder:", os.listdir(path))

video_path = '/content/drive/MyDrive/colab/ FRIENDLY.mp4'
print("File found:", os.path.exists(video_path))

!pip install ultralytics opencv-python-headless

from ultralytics import YOLO

model = YOLO('runs/detect/train/weights/best.pt')

import cv2
import os

#Extracting the video frames
video_path = '/content/drive/MyDrive/colab/ FRIENDLY.mp4'
output_dir = '/content/processed_frames'
os.makedirs(output_dir, exist_ok=True)

# Open the video
cap = cv2.VideoCapture(video_path)
frame_rate = cap.get(cv2.CAP_PROP_FPS)
frame_count = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break
#generated by generative AI
    # Process every Nth frame (e.g., 1 every 5 seconds)
    if frame_count % int(frame_rate * 5) == 0:
        frame_path = f"{output_dir}/frame_{frame_count}.jpg"
        cv2.imwrite(frame_path, frame)

        results = model.predict(source=frame_path, save=True, save_txt=True,
                                conf=0.3, project='runs', name='video_preds', exist_ok=True)

        print(f"Processed frame {frame_count}")

    frame_count += 1

cap.release()
print("âœ… Done processing selected frames.")

import IPython.display as display
from PIL import Image

# Display a frame
frame_path = 'runs/video_preds/frame_440100.jpg'
display.display(Image.open(frame_path))

#first 5 row

label_dir = 'runs/video_preds/labels'
frames_with_labels = os.listdir(label_dir)
print("Detected frames:", frames_with_labels[:5])

# display one of the frames for the video
frame_id = 'frame_166200'
img_path = f'runs/video_preds/{frame_id}.jpg'

display.display(Image.open(img_path))

import json

# Set the path to the labelled files
label_folder = "runs/video_preds/labels"
output_json = "video_predictions.json"


class_names = ["player"]

data = {}

# Loop through all label files
for file_name in os.listdir(label_folder):
    if file_name.endswith(".txt"):
        frame_id = file_name.replace(".txt", "")
        frame_path = f"processed_frames/{frame_id}.jpg"

        with open(os.path.join(label_folder, file_name), "r") as file:
            annotations = file.readlines()

        objects = []
        for line in annotations:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                x_center, y_center, width, height = map(float, parts[1:5])
                conf = float(parts[5]) if len(parts) == 6 else None

                obj = {
                    "class_id": class_id,
                    "class_name": class_names[class_id] if class_id < len(class_names) else f"class_{class_id}",
                    "bbox": {
                        "x_center": x_center,
                        "y_center": y_center,
                        "width": width,
                        "height": height
                    }
                }

                if conf is not None:
                    obj["confidence"] = conf

                objects.append(obj)

        data[frame_id] = {
            "frame_path": frame_path,
            "objects": objects
        }

# Save as JSON
with open(output_json, "w") as json_file:
    json.dump(data, json_file, indent=4)

print(f"Saved predictions to {output_json}")

# Load predictions
with open("video_predictions.json", "r") as f:
    predictions = json.load(f)

# Preview the structure
for i, (frame_id, frame_data) in enumerate(predictions.items()):
    print(f"{frame_id}: {frame_data}")
    if i == 1:
        break

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/mikel-brostrom/Yolov5_DeepSort_PyTorch.git
# %cd /content/Yolov5_DeepSort_PyTorch/Yolov5_DeepSort_PyTorch

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Yolov5_DeepSort_Pytorch

!pip install -q torch torchvision torchaudio
!pip install -q filterpy scikit-learn lap cython matplotlib opencv-python-headless

!pip install deep_sort_realtime

from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import cv2

# Load the trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/colab/best_backup.pt')

# Initialize DeepSORT
tracker = DeepSort(max_age=30)

#this section is generated by generative AI

#using deepsort to track the players and giving them unique id
tracked_results = []  # To store results for export

input_dir = '/content/processed_frames'  # the processed frames folder
frame_files = sorted(os.listdir(input_dir))

for frame_id, frame_name in enumerate(frame_files):
    frame_path = os.path.join(input_dir, frame_name)
    frame = cv2.imread(frame_path)

    results = model.predict(source=frame, conf=0.4, iou=0.5, verbose=False)[0]
    detections = []

    for box in results.boxes:
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
        conf = box.conf[0].item()
        cls_id = int(box.cls[0].item())
        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls_id))

    tracks = tracker.update_tracks(detections, frame=frame)

    for track in tracks:
        if not track.is_confirmed():
            continue

        track_id = track.track_id
        ltrb = track.to_ltrb()
        tracked_results.append({
            'frame_id': frame_id,
            'track_id': track_id,
            'x1': int(ltrb[0]),
            'y1': int(ltrb[1]),
            'x2': int(ltrb[2]),
            'y2': int(ltrb[3])
        })

import pandas as pd

df = pd.DataFrame(tracked_results)
df.to_csv('tracked_players.csv', index=False)
print("Tracking complete. Saved to 'tracked_players.csv'")

df = pd.read_csv('tracked_players.csv')
print(df.columns)
df.head()

import numpy as np
import matplotlib.pyplot as plt

# Load tracked data
df = pd.read_csv('tracked_players.csv')

# Convert to numeric
cols = ['frame_id', 'track_id', 'x1', 'y1', 'x2', 'y2']
df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')

# Compute center point of each bounding box
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Sort by track_id and frame
df = df.sort_values(by=['track_id', 'frame_id'])
#generated by generative ai
# Compute movement distance per player
distances = []
for player_id, group in df.groupby('track_id'):
    group = group.sort_values('frame_id')
    dx = group['cx'].diff().fillna(0)
    dy = group['cy'].diff().fillna(0)
    dist = np.sqrt(dx**2 + dy**2)
    total_distance = dist.sum()
    distances.append((player_id, total_distance))

# Convert to DataFrame
distance_df = pd.DataFrame(distances, columns=['Player ID', 'Distance Covered'])

# Sort by distance covered
distance_df = distance_df.sort_values(by='Distance Covered', ascending=False)

# Plot
plt.figure(figsize=(12, 6))
plt.bar(distance_df['Player ID'].astype(str), distance_df['Distance Covered'])
plt.xlabel('Player ID')
plt.ylabel('Total Distance (pixels)')
plt.title('Total Player Movement (Distance Covered)')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df['center_x'] = (df['x1'] + df['x2']) / 2
df['center_y'] = (df['y1'] + df['y2']) / 2

df['dx'] = df.groupby('track_id')['center_x'].diff()
df['dy'] = df.groupby('track_id')['center_y'].diff()

df['distance'] = np.sqrt(df['dx']**2 + df['dy']**2)


avg_speed_per_player = df.groupby('track_id')['distance'].mean().sort_values(ascending=False)
peak_speed_per_player = df.groupby('track_id')['distance'].max().sort_values(ascending=False)

#generated by generative ai

# Load the tracking data
df = pd.read_csv('tracked_players.csv')

# Convert columns to numeric (in case they aren't)
cols = ['frame_id', 'track_id', 'x1', 'y1', 'x2', 'y2']
df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')

# Compute center point of each bounding box (player position)
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Sort by track_id and frame_id for correct frame-by-frame comparison
df = df.sort_values(by=['track_id', 'frame_id'])

# Compute distance and speed per frame
df['dx'] = df.groupby('track_id')['cx'].diff()
df['dy'] = df.groupby('track_id')['cy'].diff()
df['distance'] = np.sqrt(df['dx']**2 + df['dy']**2)
df['speed'] = df['distance']  # Assuming 1 frame = 1 time unit (e.g., 1/30 sec)

# Total Distance Covered (per player)
total_distance = df.groupby('track_id')['distance'].sum().sort_values(ascending=False)

plt.figure(figsize=(6, 4))
total_distance.plot(kind='bar')
plt.title('Total Player Movement (Distance Covered)')
plt.xlabel('Player ID')
plt.ylabel('Total Distance (pixels)')
plt.tight_layout()
plt.show()

# Average Speed per Player (Workload Intensity)
avg_speed = df.groupby('track_id')['speed'].mean().sort_values(ascending=False)

plt.figure(figsize=(6, 4))
avg_speed.plot(kind='bar', color='orange')
plt.title('Average Speed per Player')
plt.xlabel('Player ID')
plt.ylabel('Speed (pixels/frame)')
plt.tight_layout()
plt.show()

#  Save final data
df.to_csv('player_physical_metrics.csv', index=False)

# Load tracked data
df = pd.read_csv('tracked_players.csv')

# Convert to numeric in case any column is string type
cols = ['frame_id', 'track_id', 'x1', 'y1', 'x2', 'y2']
df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')

# Compute center point of each bounding box
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Sort data by track and frame to keep motion order
df = df.sort_values(by=['track_id', 'frame_id'])

# Compute distance and speed per frame
df['dx'] = df.groupby('track_id')['cx'].diff()
df['dy'] = df.groupby('track_id')['cy'].diff()
df['distance'] = np.sqrt(df['dx']**2 + df['dy']**2)
df['speed'] = df['distance']  # assuming 1 frame = 1 time unit

# Group by player (track_id) to calculate total distance, avg speed, and workload
summary = df.groupby('track_id').agg(
    total_distance=('distance', 'sum'),
    average_speed=('speed', 'mean'),
    workload=('frame_id', 'count')
).reset_index()

# Save results
summary.to_csv('player_physical_metrics.csv', index=False)

# Plot total distance
plt.figure(figsize=(14, 5))
summary.sort_values('total_distance', ascending=False, inplace=True)
plt.bar(summary['track_id'].astype(str), summary['total_distance'])
plt.title('Total Player Movement (Distance Covered)')
plt.xlabel('Player ID')
plt.ylabel('Total Distance (pixels)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plot average speed
plt.figure(figsize=(14, 5))
summary.sort_values('average_speed', ascending=False, inplace=True)
plt.bar(summary['track_id'].astype(str), summary['average_speed'], color='orange')
plt.title('Average Speed per Player')
plt.xlabel('Player ID')
plt.ylabel('Speed (pixels/frame)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plot workload
plt.figure(figsize=(14, 5))
summary.sort_values('workload', ascending=False, inplace=True)
plt.bar(summary['track_id'].astype(str), summary['workload'], color='green')
plt.title('Workload per Player (Frame Count)')
plt.xlabel('Player ID')
plt.ylabel('Frame Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#generated by generative AI
# Load data
df = pd.read_csv('tracked_players.csv')

# Convert to numeric (in case any column is string type)
cols = ['frame_id', 'track_id', 'x1', 'y1', 'x2', 'y2']
df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')

# Compute center of bounding boxes
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Sort for proper frame-wise analysis
df.sort_values(by=['track_id', 'frame_id'], inplace=True)

# Compute distance moved between frames
df['dx'] = df.groupby('track_id')['cx'].diff()
df['dy'] = df.groupby('track_id')['cy'].diff()
df['distance'] = np.sqrt(df['dx']**2 + df['dy']**2)

# Replace NaNs with 0
df['distance'].fillna(0, inplace=True)

# Compute speed (distance per frame)
df['speed'] = df['distance']  # Assuming 1 frame = 1 unit time

# Compute metrics per player
metrics = df.groupby('track_id').agg({
    'distance': 'sum',
    'speed': 'mean',
    'frame_id': 'count'
}).rename(columns={'distance': 'total_distance', 'speed': 'avg_speed', 'frame_id': 'workload'}).reset_index()

# Normalize for intensity score (0â€“100 scale)
metrics['norm_distance'] = (metrics['total_distance'] - metrics['total_distance'].min()) / (metrics['total_distance'].max() - metrics['total_distance'].min())
metrics['norm_speed'] = (metrics['avg_speed'] - metrics['avg_speed'].min()) / (metrics['avg_speed'].max() - metrics['avg_speed'].min())
metrics['intensity'] = 0.5 * (metrics['norm_distance'] + metrics['norm_speed']) * 100

# Save to CSV (optional)
metrics.to_csv('player_physical_metrics.csv', index=False)

# Distance Covered
plt.figure(figsize=(6, 4))
plt.bar(metrics['track_id'].astype(str), metrics['total_distance'], color='blue')
plt.xticks(rotation=90)
plt.ylabel("Total Distance (pixels)")
plt.xlabel('Player ID')
plt.title("Total Player Movement (Distance Covered)")
plt.tight_layout()
plt.show()

# Average Speed
plt.figure(figsize=(6, 4))
plt.bar(metrics['track_id'].astype(str), metrics['avg_speed'], color='orange')
plt.xticks(rotation=90)
plt.ylabel("Avg Speed (pixels/frame)")
plt.xlabel('Player ID')
plt.title("Average Speed per Player")
plt.tight_layout()
plt.show()

# Workload (frames seen)
plt.figure(figsize=(6, 4))
plt.bar(metrics['track_id'].astype(str), metrics['workload'], color='green')
plt.xticks(rotation=90)
plt.ylabel("Frame Count")
plt.xlabel('Player ID')
plt.title("Workload per Player (Frame Count)")
plt.tight_layout()
plt.show()

# Intensity Score
plt.figure(figsize=(6, 4))
plt.bar(metrics['track_id'].astype(str), metrics['intensity'], color='purple')
plt.xticks(rotation=90)
plt.ylabel("Intensity Score (0-100)")
plt.xlabel('Player ID')
plt.title("Overall Intensity Score per Player")
plt.tight_layout()
plt.show()

import pandas as pd

# Load player physical metrics
df = pd.read_csv('player_physical_metrics.csv')
df.head()

# Load the player tracking data
df = pd.read_csv("tracked_players.csv")

# Compute the center of the bounding boxes
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Get the top 3 unique frames with the most players
frame_counts = df['frame_id'].value_counts().sort_values(ascending=False)
unique_top_frames = frame_counts.drop_duplicates().head(3).index.tolist()

# Filter the data for those frames
shapes = df[df['frame_id'].isin(unique_top_frames)]

# Plot player positions in each frame
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for i, frame in enumerate(unique_top_frames):
    frame_data = shapes[shapes['frame_id'] == frame]
    axes[i].scatter(frame_data['cx'], frame_data['cy'], c='blue', s=100)

    # Add player ID labels inside the circles
    for _, row in frame_data.iterrows():
        axes[i].text(
            row['cx'], row['cy'], str(int(row['track_id'])),
            fontsize=9, ha='center', va='center', color='white',
            bbox=dict(facecolor='black', edgecolor='none', boxstyle='circle')
        )

    axes[i].invert_yaxis()
    axes[i].set_title(f'Team Shape - Frame {frame}')
    axes[i].set_xlabel("X Position")
    axes[i].set_ylabel("Y Position")
    axes[i].grid(True)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the tracking data
df = pd.read_csv("tracked_players.csv")

# Calculate center positions from bounding boxes
df['cx'] = (df['x1'] + df['x2']) / 2
df['cy'] = (df['y1'] + df['y2']) / 2

# Sort values by player and time
df = df.sort_values(by=['track_id', 'frame_id'])

# Compute displacement and speed
df['dx'] = df.groupby('track_id')['cx'].diff()
df['dy'] = df.groupby('track_id')['cy'].diff()
df['distance'] = np.sqrt(df['dx']**2 + df['dy']**2)
df['speed'] = df['distance'].fillna(0)

# Compute acceleration (change in speed over time)
df['acceleration'] = df.groupby('track_id')['speed'].diff().fillna(0)

# Visualise acceleration for 3 sample players
sample_ids = df['track_id'].dropna().unique()[:3]

plt.figure(figsize=(10, 4))
for tid in sample_ids:
    subset = df[df['track_id'] == tid]
    plt.plot(subset['frame_id'], subset['acceleration'], label=f'Player {tid}')

plt.title("Acceleration Over Time for Sample Players")
plt.xlabel("Frame")
plt.ylabel("Acceleration")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

